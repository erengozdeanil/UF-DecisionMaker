{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Tools\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gives adjacency dictionary (not mine)\n",
    "edge_dict={}\n",
    "def create_edge_dict(graph):\n",
    "    for i, n in G.adjacency():\n",
    "        # print(\"i is\",i)\n",
    "        # print(\"n is\",n)\n",
    "        edge_dict[i] = list(n)\n",
    "    return edge_dict\n",
    "\n",
    "# Gives duplicate items in a list (not mine)\n",
    "def list_duplicates(seq):\n",
    "  seen = set()\n",
    "  seen_add = seen.add\n",
    "  # adds all elements it doesn't know yet to seen and all other to seen_twice\n",
    "  seen_twice = set( x for x in seq if x in seen or seen_add(x) )\n",
    "  # turn the set into a list (as requested)\n",
    "  return list( seen_twice )\n",
    "\n",
    "\n",
    "#(https://www.geeksforgeeks.org/python-merge-two-lists-into-list-of-tuples/)\n",
    "def merge(list1, list2):\n",
    "      \n",
    "    merged_list = []\n",
    "    for i in range(max((len(list1), len(list2)))):\n",
    "  \n",
    "        while True:\n",
    "            try:\n",
    "                tup = (list1[i], list2[i])\n",
    "            except IndexError:\n",
    "                if len(list1) > len(list2):\n",
    "                    list2.append('')\n",
    "                    tup = (list1[i], list2[i])\n",
    "                elif len(list1) < len(list2):\n",
    "                    list1.append('')\n",
    "                    tup = (list1[i], list2[i])\n",
    "                continue\n",
    "  \n",
    "            merged_list.append(tup)\n",
    "            break\n",
    "    return merged_list\n",
    "\n",
    "\n",
    "# function to check whether the list is empty or not\n",
    "def is_list_empty(list):\n",
    "    # checking the length\n",
    "    if len(list) == 0:\n",
    "        # returning true as length is 0\n",
    "        return True\n",
    "    # returning false as length is greater than 0\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/erengozdeanil/UF-DecisionMaker/main/vacant%20spaces_bigger%20radius.txt\"\n",
    "resp = requests.get(url)\n",
    "vacant_spaces = json.loads(resp.text)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/erengozdeanil/UF-DecisionMaker/main/available%20waste%202.txt\"\n",
    "resp = requests.get(url)\n",
    "wastes = json.loads(resp.text)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/erengozdeanil/UF-DecisionMaker/main/available%20waste%202.txt\"\n",
    "resp = requests.get(url)\n",
    "occupied_nodes = json.loads(resp.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve connections between vacant spaces within radius=x\n",
    "url1=\"https://raw.githubusercontent.com/erengozdeanil/UF-DecisionMaker/main/Edges_vacant200.txt\"\n",
    "resp1 = requests.get(url1)\n",
    "edges1 = json.loads(resp1.text)\n",
    "#converts nested lists into a list of tuples\n",
    "nearby_space100  = [tuple(i) for i in edges1]\n",
    "\n",
    "#retrieve connections within radius=x with identifiers\n",
    "url1=\"https://raw.githubusercontent.com/erengozdeanil/UF-DecisionMaker/main/Edges_try2.txt\"\n",
    "resp1 = requests.get(url1)\n",
    "edges1 = json.loads(resp1.text)\n",
    "#converts nested lists into a list of tuples\n",
    "nearby_waste100 = [tuple(i) for i in edges1]\n",
    "# print(waste_nearby100,len(waste_nearby100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('V2', 'WO44')\n",
      "('V2', 'WO15')\n",
      "('V2', 'WO34')\n",
      "('V2', 'WO47')\n",
      "('V2', 'WO24')\n",
      "('V2', 'WO32')\n"
     ]
    }
   ],
   "source": [
    "#NOTE : SHOULD REMOVE OCCUPIED VACANT SPACES, AND USED WASTE SOURCES FROM THE DICTIONARIES\n",
    "\n",
    "for index,couple in enumerate(nearby_waste100):\n",
    "    if couple[0] not in vacant_spaces:\n",
    "        nearby_waste100.pop(index)\n",
    "\n",
    "for index,couple in enumerate(nearby_waste100):\n",
    "    if couple[1] not in vacant_spaces:\n",
    "        nearby_waste100.pop(index)\n",
    "\n",
    "for index,couple in enumerate(nearby_space100):\n",
    "    if couple[0] not in vacant_spaces:\n",
    "        nearby_space100.pop(index)\n",
    "\n",
    "\n",
    "for index,couple in enumerate(nearby_space100):\n",
    "    if couple[1] not in vacant_spaces:\n",
    "        nearby_space100.pop(index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('V0', 'WO77'), ('V0', 'WO76'), ('V0', 'WO79'), ('V1', 'WO56'), ('V1', 'WO54'), ('V1', 'WO48'), ('V1', 'WO84'), ('V1', 'WO24'), ('V1', 'WO25'), ('V1', 'WO49'), ('V1', 'WO0'), ('V1', 'WO18'), ('V1', 'WO15'), ('V1', 'WO65'), ('V2', 'WO44'), ('V2', 'WO15'), ('V2', 'WO34'), ('V2', 'WO47'), ('V2', 'WO24'), ('V2', 'WO32'), ('V3', 'WO42'), ('V3', 'WO2'), ('V3', 'WO4'), ('V5', 'WO53'), ('V5', 'WO51'), ('V5', 'WO50'), ('V5', 'WO59'), ('V5', 'WO49'), ('V5', 'WO83'), ('V5', 'WO65'), ('V5', 'WO64'), ('V5', 'WO57'), ('V5', 'WO63'), ('V5', 'WO84'), ('V6', 'WO2'), ('V6', 'WO1'), ('V6', 'WO8'), ('V6', 'WO7'), ('V6', 'WO3'), ('V8', 'WO27'), ('V8', 'WO23'), ('V8', 'WO21'), ('V8', 'WO10'), ('V8', 'WO54'), ('V9', 'WO81'), ('V9', 'WO78'), ('V9', 'WO76'), ('V10', 'WO68'), ('V10', 'WO62'), ('V10', 'WO61'), ('V10', 'WO67'), ('V10', 'WO65'), ('V10', 'WO58'), ('V10', 'WO55'), ('V11', 'WO70'), ('V13', 'WO37'), ('V13', 'WO35'), ('V13', 'WO41'), ('V13', 'WO18'), ('V13', 'WO39'), ('V13', 'WO24'), ('V13', 'WO16'), ('V13', 'WO34'), ('V13', 'WO44'), ('V13', 'WO25'), ('V13', 'WO12'), ('V13', 'WO45'), ('V13', 'WO46'), ('V13', 'WO33'), ('V13', 'WO47'), ('V13', 'WO31'), ('V14', 'WO10'), ('V14', 'WO13'), ('V14', 'WO23'), ('V14', 'WO25'), ('V14', 'WO20'), ('V14', 'WO24'), ('V16', 'WO71'), ('V18', 'WO72'), ('V19', 'WO70'), ('V21', 'WO52'), ('V22', 'WO66'), ('V22', 'WO61'), ('V22', 'WO62'), ('V22', 'WO53'), ('V22', 'WO56'), ('V22', 'WO72'), ('V23', 'WO45'), ('V23', 'WO43'), ('V23', 'WO41'), ('V23', 'WO46'), ('V23', 'WO15'), ('V23', 'WO37'), ('V23', 'WO35'), ('V23', 'WO31'), ('V23', 'WO32'), ('V23', 'WO85'), ('V23', 'WO17'), ('V24', 'WO59'), ('V24', 'WO60'), ('V24', 'WO84'), ('V24', 'WO64'), ('V24', 'WO63'), ('V25', 'WO0'), ('V25', 'WO26'), ('V25', 'WO24'), ('V25', 'WO56'), ('V25', 'WO10'), ('V25', 'WO23'), ('V25', 'WO12'), ('V25', 'WO22'), ('V27', 'WO0'), ('V27', 'WO54'), ('V27', 'WO64'), ('V27', 'WO67'), ('V27', 'WO55'), ('V27', 'WO62'), ('V27', 'WO58'), ('V27', 'WO66'), ('V28', 'WO20'), ('V28', 'WO21'), ('V28', 'WO13'), ('V28', 'WO23'), ('V28', 'WO35'), ('V28', 'WO38'), ('V28', 'WO33'), ('V28', 'WO10'), ('V28', 'WO36'), ('V29', 'WO83'), ('V29', 'WO52'), ('V29', 'WO69'), ('V29', 'WO50'), ('V29', 'WO60'), ('V30', 'WO70'), ('V30', 'WO52'), ('V30', 'WO51'), ('V31', 'WO80'), ('V32', 'WO75'), ('V32', 'WO77'), ('V33', 'WO71'), ('V35', 'WO74'), ('V38', 'WO83'), ('V38', 'WO69'), ('V38', 'WO53'), ('V39', 'WO70'), ('V39', 'WO69'), ('V39', 'WO53'), ('V39', 'WO60'), ('V41', 'WO79'), ('V41', 'WO78'), ('V41', 'WO80'), ('V41', 'WO81'), ('V43', 'WO74'), ('V44', 'WO56'), ('V44', 'WO63'), ('V44', 'WO59'), ('V44', 'WO27'), ('V44', 'WO26'), ('V45', 'WO71'), ('V47', 'WO74'), ('V49', 'WO76'), ('V49', 'WO77'), ('V49', 'WO78'), ('V50', 'WO83'), ('V50', 'WO52'), ('V51', 'WO86'), ('V51', 'WO49'), ('V52', 'WO78'), ('V52', 'WO77'), ('V52', 'WO81'), ('V52', 'WO76'), ('V53', 'WO0'), ('V53', 'WO56'), ('V53', 'WO63'), ('V53', 'WO67'), ('V53', 'WO65'), ('V53', 'WO58'), ('V53', 'WO61'), ('V53', 'WO66'), ('V53', 'WO48'), ('V54', 'WO85'), ('V54', 'WO14'), ('V55', 'WO69'), ('V55', 'WO52'), ('V56', 'WO74'), ('V57', 'WO83'), ('V57', 'WO53'), ('V57', 'WO49'), ('V57', 'WO70'), ('V58', 'WO52'), ('V58', 'WO50'), ('V58', 'WO49'), ('V59', 'WO49'), ('V59', 'WO51'), ('V59', 'WO52'), ('V59', 'WO85'), ('V59', 'WO48'), ('V60', 'WO52'), ('V60', 'WO49'), ('V60', 'WO59'), ('V60', 'WO84'), ('V61', 'WO50'), ('V61', 'WO51'), ('V61', 'WO52'), ('V61', 'WO53'), ('V61', 'WO85'), ('V61', 'WO83'), ('V62', 'WO52'), ('V62', 'WO53'), ('V62', 'WO49'), ('V63', 'WO50'), ('V63', 'WO51'), ('V63', 'WO52'), ('V63', 'WO53'), ('V63', 'WO85'), ('V63', 'WO83'), ('V64', 'WO52'), ('V64', 'WO49'), ('V64', 'WO83'), ('V64', 'WO84'), ('V65', 'WO70'), ('V65', 'WO60'), ('V66', 'WO78'), ('V66', 'WO79'), ('V66', 'WO76'), ('V67', 'WO84'), ('V67', 'WO85'), ('V67', 'WO15'), ('V67', 'WO59'), ('V67', 'WO54'), ('V67', 'WO50'), ('V67', 'WO26'), ('V67', 'WO55'), ('V67', 'WO51'), ('V67', 'WO37'), ('V68', 'WO1'), ('V68', 'WO7'), ('V68', 'WO2'), ('V68', 'WO6'), ('V68', 'WO4'), ('V71', 'WO72'), ('V71', 'WO68'), ('V71', 'WO67'), ('V71', 'WO61'), ('V71', 'WO64'), ('V71', 'WO66'), ('V71', 'WO55'), ('V72', 'WO80'), ('V72', 'WO79'), ('V72', 'WO75'), ('V73', 'WO73'), ('V73', 'WO68'), ('V73', 'WO62'), ('V73', 'WO65'), ('V73', 'WO64'), ('V73', 'WO66'), ('V75', 'WO85'), ('V75', 'WO14'), ('V75', 'WO44'), ('V75', 'WO41'), ('V75', 'WO37'), ('V77', 'WO71'), ('V78', 'WO32'), ('V78', 'WO47'), ('V78', 'WO34'), ('V78', 'WO36'), ('V78', 'WO43'), ('V78', 'WO33'), ('V78', 'WO38'), ('V79', 'WO26'), ('V79', 'WO25'), ('V79', 'WO54'), ('V79', 'WO18'), ('V79', 'WO57'), ('V79', 'WO48'), ('V79', 'WO64'), ('V79', 'WO22'), ('V80', 'WO80'), ('V80', 'WO78'), ('V83', 'WO85'), ('V83', 'WO48'), ('V83', 'WO86'), ('V83', 'WO49'), ('V83', 'WO41'), ('V83', 'WO43'), ('V83', 'WO26'), ('V83', 'WO37'), ('V83', 'WO45'), ('V83', 'WO57'), ('V84', 'WO76'), ('V87', 'WO50'), ('V87', 'WO49'), ('V88', 'WO85'), ('V88', 'WO15'), ('V90', 'WO74'), ('V91', 'WO52'), ('V91', 'WO50'), ('V92', 'WO52'), ('V93', 'WO50'), ('V93', 'WO86'), ('V93', 'WO59'), ('V93', 'WO85'), ('V93', 'WO53'), ('V94', 'WO51'), ('V94', 'WO50'), ('V94', 'WO59'), ('V94', 'WO60'), ('V94', 'WO84'), ('V94', 'WO48'), ('V95', 'WO83'), ('V95', 'WO51'), ('V95', 'WO50'), ('V95', 'WO59'), ('V96', 'WO73'), ('V96', 'WO62'), ('V97', 'WO72'), ('V97', 'WO62'), ('V97', 'WO60'), ('V97', 'WO65'), ('V98', 'WO0'), ('V98', 'WO67'), ('V98', 'WO73'), ('V98', 'WO65'), ('V98', 'WO54'), ('V99', 'WO83'), ('V99', 'WO51'), ('V99', 'WO50'), ('V99', 'WO59'), ('V100', 'WO5'), ('V100', 'WO42'), ('V100', 'WO6'), ('V100', 'WO4'), ('V100', 'WO3'), ('V101', 'WO50'), ('V101', 'WO59'), ('V101', 'WO52'), ('V101', 'WO48'), ('V101', 'WO86'), ('V102', 'WO71'), ('V103', 'WO79'), ('V104', 'WO51'), ('V104', 'WO50'), ('V104', 'WO53'), ('V104', 'WO83'), ('V104', 'WO48'), ('V106', 'WO45'), ('V106', 'WO46'), ('V106', 'WO14'), ('V106', 'WO32'), ('V106', 'WO47'), ('V106', 'WO39'), ('V106', 'WO15'), ('V106', 'WO33'), ('V108', 'WO74'), ('V110', 'WO69'), ('V112', 'WO31'), ('V112', 'WO45'), ('V112', 'WO47'), ('V112', 'WO34'), ('V112', 'WO14'), ('V112', 'WO39'), ('V113', 'WO81'), ('V115', 'WO81'), ('V115', 'WO78'), ('V115', 'WO77'), ('V115', 'WO76'), ('V116', 'WO73'), ('V117', 'WO74'), ('V117', 'WO75'), ('V117', 'WO79'), ('V118', 'WO77'), ('V118', 'WO76'), ('V118', 'WO78'), ('V119', 'WO63'), ('V119', 'WO64'), ('V119', 'WO67'), ('V120', 'WO68'), ('V120', 'WO73'), ('V120', 'WO61'), ('V120', 'WO67'), ('V120', 'WO66'), ('V120', 'WO58'), ('V120', 'WO55'), ('V121', 'WO20'), ('V121', 'WO19'), ('V121', 'WO23'), ('V121', 'WO13'), ('V121', 'WO40'), ('V121', 'WO11'), ('V121', 'WO18'), ('V121', 'WO36'), ('V121', 'WO37'), ('V121', 'WO24'), ('V121', 'WO25'), ('V121', 'WO41'), ('V121', 'WO46'), ('V122', 'WO6'), ('V122', 'WO42'), ('V122', 'WO2'), ('V122', 'WO8'), ('V124', 'WO27'), ('V124', 'WO0'), ('V124', 'WO54'), ('V124', 'WO57'), ('V124', 'WO64'), ('V124', 'WO63'), ('V124', 'WO65'), ('V124', 'WO17'), ('V124', 'WO58'), ('V125', 'WO75'), ('V125', 'WO79'), ('V125', 'WO78'), ('V128', 'WO76'), ('V128', 'WO77'), ('V128', 'WO78'), ('V129', 'WO8'), ('V129', 'WO3'), ('V129', 'WO42'), ('V129', 'WO7'), ('V130', 'WO45'), ('V130', 'WO46'), ('V130', 'WO43'), ('V130', 'WO34'), ('V130', 'WO36'), ('V130', 'WO41'), ('V130', 'WO38'), ('V130', 'WO35'), ('V130', 'WO33'), ('V130', 'WO86'), ('V131', 'WO72'), ('V131', 'WO62'), ('V131', 'WO60'), ('V131', 'WO65'), ('V131', 'WO63'), ('V133', 'WO71'), ('V135', 'WO82'), ('V136', 'WO59'), ('V136', 'WO55'), ('V136', 'WO56'), ('V136', 'WO64'), ('V136', 'WO63'), ('V136', 'WO62'), ('V137', 'WO63'), ('V137', 'WO67'), ('V137', 'WO65'), ('V137', 'WO57'), ('V137', 'WO55'), ('V137', 'WO73'), ('V137', 'WO61'), ('V138', 'WO16'), ('V138', 'WO21'), ('V138', 'WO22'), ('V138', 'WO13'), ('V138', 'WO12'), ('V138', 'WO38'), ('V138', 'WO17'), ('V138', 'WO39'), ('V138', 'WO18'), ('V138', 'WO34'), ('V138', 'WO47'), ('V138', 'WO24'), ('V139', 'WO63'), ('V139', 'WO64'), ('V139', 'WO62'), ('V139', 'WO72'), ('V139', 'WO73'), ('V139', 'WO55'), ('V141', 'WO74'), ('V142', 'WO75'), ('V142', 'WO77'), ('V142', 'WO80'), ('V142', 'WO74'), ('V143', 'WO63'), ('V143', 'WO67'), ('V143', 'WO54'), ('V143', 'WO65'), ('V145', 'WO9'), ('V145', 'WO11'), ('V145', 'WO12'), ('V145', 'WO23'), ('V145', 'WO19')] 481\n"
     ]
    }
   ],
   "source": [
    "for waste in wastes:\n",
    "    for couple in nearby_waste100:\n",
    "        if wastes[waste][\"type\"]==\"None\":\n",
    "            if waste in couple:\n",
    "                print(couple, \"removed\")\n",
    "                nearby_waste100.remove(couple)\n",
    "                (couple,\"removed\")\n",
    "print(nearby_waste100,len(nearby_waste100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = load_workbook(filename=\"Node_Information_TU.xlsx\")\n",
    "workbook.sheetnames\n",
    "sheet1 = workbook.worksheets[0]\n",
    "sheet2 = workbook.worksheets[1]\n",
    "wastes={}\n",
    "for value in sheet2.iter_rows(min_row=2, values_only=True):\n",
    "    for index,item in enumerate(value):\n",
    "        if value[4]!=0:\n",
    "            wastes[value[0]]={}\n",
    "            wastes[value[0]][\"location\"]=value[1]\n",
    "            wastes[value[0]][\"source\"]=value[2]\n",
    "            wastes[value[0]][\"tag\"]=value[5]\n",
    "            wastes[value[0]][\"type\"]=value[3]\n",
    "            wastes[value[0]][\"quantity\"]=int(value[4])\n",
    "            wastes[value[0]][\"node_type\"]=\"waste\"\n",
    "\n",
    "\n",
    "#assign ranges to quantities\n",
    "for waste in wastes:\n",
    "    if wastes[waste][\"type\"]==\"W1\":\n",
    "        if wastes[waste][\"quantity\"]<= 91852:\n",
    "            wastes[waste][\"size\"]=1\n",
    "        if (wastes[waste][\"quantity\"]>91852) and (wastes[waste][\"quantity\"]<=459261):\n",
    "            wastes[waste][\"size\"]=2\n",
    "        if wastes[waste][\"quantity\"]>459261:\n",
    "            wastes[waste][\"size\"]=3\n",
    "    if wastes[waste][\"type\"]==\"W2\":\n",
    "        if wastes[waste][\"quantity\"]<= 25000:\n",
    "            wastes[waste][\"size\"]=1\n",
    "        if (wastes[waste][\"quantity\"]>25000) and (wastes[waste][\"quantity\"]<=125000):\n",
    "            wastes[waste][\"size\"]=2\n",
    "        if wastes[waste][\"quantity\"]>125000:\n",
    "            wastes[waste][\"size\"]=3\n",
    "    if wastes[waste][\"type\"]==\"W3\":\n",
    "        if wastes[waste][\"quantity\"]<= 5906:\n",
    "            wastes[waste][\"size\"]=1\n",
    "        if (wastes[waste][\"quantity\"]>5906) and (wastes[waste][\"quantity\"]<=29531):\n",
    "            wastes[waste][\"size\"]=2\n",
    "        if wastes[waste][\"quantity\"]>29531:\n",
    "            wastes[waste][\"size\"]=3\n",
    "    if wastes[waste][\"type\"]==\"W4\":\n",
    "        if wastes[waste][\"quantity\"]<= 14100:\n",
    "            wastes[waste][\"size\"]=1\n",
    "        if (wastes[waste][\"quantity\"]>14100) and (wastes[waste][\"quantity\"]<=70500):\n",
    "            wastes[waste][\"size\"]=2\n",
    "        if wastes[waste][\"quantity\"]>70500:\n",
    "            wastes[waste][\"size\"]=3\n",
    "    if wastes[waste][\"type\"]==\"W5\":\n",
    "        if wastes[waste][\"quantity\"]<= 7937:\n",
    "            wastes[waste][\"size\"]=1\n",
    "        if (wastes[waste][\"quantity\"]>7937) and (wastes[waste][\"quantity\"]<=39684):\n",
    "            wastes[waste][\"size\"]=2\n",
    "        if wastes[waste][\"quantity\"]>39684:\n",
    "            wastes[waste][\"size\"]=3\n",
    "    if wastes[waste][\"type\"]==\"W6\":\n",
    "        if wastes[waste][\"quantity\"]<= 187612:\n",
    "            wastes[waste][\"size\"]=1\n",
    "        if (wastes[waste][\"quantity\"]>187612) and (wastes[waste][\"quantity\"]<=938060):\n",
    "            wastes[waste][\"size\"]=2\n",
    "        if wastes[waste][\"quantity\"]>938060:\n",
    "            wastes[waste][\"size\"]=3\n",
    "    if wastes[waste][\"type\"]==\"W7\":\n",
    "        if wastes[waste][\"quantity\"]<= 100000:\n",
    "            wastes[waste][\"size\"]=1\n",
    "        if (wastes[waste][\"quantity\"]>100000) and (wastes[waste][\"quantity\"]<=500000):\n",
    "            wastes[waste][\"size\"]=2\n",
    "        if wastes[waste][\"quantity\"]>500000:\n",
    "            wastes[waste][\"size\"]=3\n",
    "# #remove quantity\n",
    "for waste in wastes:\n",
    "    wastes[waste].pop(\"quantity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary of urban farming systems\n",
    "    # UF1: Vermiculture, UF2: Aquaculture, UF3: Mushroom, UF4: NFT, UF5: Medai Beds, UF6: Raised Beds, UF7: Water Culture, UF8: Plant Factory, UF9: Aeroponics\n",
    "    # \"S\" : supplementary system, \"F\" : food production system\n",
    "    # 3 : high, 2 : medium, 1 : low, 0 : none\n",
    "uf_systems = {\n",
    "\"UF1\":{\"tag\":\"UF1\",\"type\":\"S\",\"weight\":3,\"solar\":1,\"in\":[\"W1\",\"W2\",\"W3\",\"W6\"],\"supplement\":None,\"out\":[\"S4\",\"S5\"]},\n",
    "\"UF2\":{\"tag\":\"UF2\",\"type\":\"SF\",\"weight\":3,\"solar\":2,\"in\":[\"W7\"],\"supplement\":[\"S5\"],\"out\":[\"O4\",\"S2\"]},\n",
    "\"UF3\":{\"tag\":\"UF3\",\"type\":\"F\",\"weight\":2,\"solar\":1,\"in\":[\"W2\",\"W3\",\"W4\",\"W6\"],\"supplement\":None,\"out\":[\"O3\",\"S4\"]},\n",
    "\"UF4\":{\"tag\":\"UF4\",\"type\":\"F\",\"weight\":1,\"solar\":3,\"in\":[\"W5\",\"W6\",\"W7\"],\"supplement\":[\"S2\"],\"out\":[\"O1\",\"W1\"]},\n",
    "\"UF5\":{\"tag\":\"UF5\",\"type\":\"F\",\"weight\":1,\"solar\":3,\"in\":[\"W5\",\"W6\",\"W7\"],\"supplement\":[\"S2\"],\"out\":[\"O1\",\"O2\",\"W1\"]},\n",
    "\"UF6\":{\"tag\":\"UF6\",\"type\":\"F\",\"weight\":3,\"solar\":3,\"in\":[\"W6\"],\"supplement\":[\"S4\"],\"out\":[\"O1\",\"O2\",\"W1\"]},\n",
    "\"UF7\":{\"tag\":\"UF7\",\"type\":\"F\",\"weight\":3,\"solar\":3,\"in\":[\"W5\",\"W6\",\"W7\"],\"supplement\":[\"S2\"],\"out\":[\"O1\",\"W1\"]},\n",
    "\"UF8\":{\"tag\":\"UF8\",\"type\":\"F\",\"weight\":3,\"solar\":1,\"in\":[\"W5\",\"W6\"],\"supplement\":[\"S2\"],\"out\":[\"O1\",\"W1\",\"W7\"]},\n",
    "\"UF9\":{\"tag\":\"UF9\",\"type\":\"F\",\"weight\":1,\"solar\":3,\"in\":[\"W5\",\"W6\",\"W7\"],\"supplement\":[\"S2\"],\"out\":[\"O1\",\"W1\"]}\n",
    "}\n",
    "\n",
    "critical_items=[\"W1\",\"W2\",\"W3\", \"W4\"]\n",
    "non_critical_items=[\"W5\",\"W6\",\"W7\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Prepare Data For Decision Making"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('V0', 'WO77') outside fellowship W5\n",
      "('V0', 'WO77') W5\n",
      "removed ('V0', 'WO77') W5 outside fellowship W5\n",
      "('V0', 'WO77') outside fellowship W5\n",
      "('V0', 'WO77') not in nearby_waste100\n",
      "('V0', 'WO79') outside AE W3\n",
      "('V0', 'WO79') outside AE W3\n",
      "('V0', 'WO79') not in nearby_waste100\n",
      "('V1', 'WO56') outside CEG W5\n",
      "('V1', 'WO56') W5\n",
      "removed ('V1', 'WO56') W5 outside CEG W5\n",
      "('V1', 'WO56') outside CEG W5\n",
      "('V1', 'WO56') not in nearby_waste100\n",
      "('V1', 'WO48') outside EEMCS2 W4\n",
      "('V1', 'WO48') outside EEMCS2 W4\n",
      "('V1', 'WO48') not in nearby_waste100\n",
      "('V1', 'WO84') outside EEMCS2 W1\n",
      "('V1', 'WO84') outside EEMCS2 W1\n",
      "('V1', 'WO84') not in nearby_waste100\n",
      "('V1', 'WO24') outside AS W5\n",
      "('V1', 'WO24') W5\n",
      "removed ('V1', 'WO24') W5 outside AS W5\n",
      "('V1', 'WO24') outside AS W5\n",
      "('V1', 'WO24') not in nearby_waste100\n",
      "('V1', 'WO49') outside EEMCS2 W5\n",
      "('V1', 'WO49') W5\n",
      "removed ('V1', 'WO49') W5 outside EEMCS2 W5\n",
      "('V1', 'WO49') outside EEMCS2 W5\n",
      "('V1', 'WO49') not in nearby_waste100\n",
      "('V1', 'WO18') outside AS W5\n",
      "('V1', 'WO18') W5\n",
      "removed ('V1', 'WO18') W5 outside AS W5\n",
      "('V1', 'WO18') outside AS W5\n",
      "('V1', 'WO18') not in nearby_waste100\n",
      "('V1', 'WO65') outside CEG W4\n",
      "('V1', 'WO65') outside CEG W4\n",
      "('V1', 'WO65') not in nearby_waste100\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'V2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29356/1480102161.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcouple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mvacant_spaces\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcouple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"building\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0mwastes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcouple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"source\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcouple\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvacant_spaces\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcouple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"building\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwastes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcouple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"source\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwastes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcouple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwastes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcouple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"W5\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwastes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcouple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"W6\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mwastes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcouple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"W7\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'V2'"
     ]
    }
   ],
   "source": [
    "#Make a dictionary of vacant spaces and potential uf systems\n",
    "v_potential = {}\n",
    "for k,v in vacant_spaces.items():\n",
    "    uf_list=[]\n",
    "    for j,y in uf_systems.items():\n",
    "        if (vacant_spaces[k][\"structure\"])>=(uf_systems[j][\"weight\"]) and (vacant_spaces[k][\"solar\"])==(uf_systems[j][\"solar\"]) and (uf_systems[j][\"type\"]==\"F\"):\n",
    "            v_potential[k]={}\n",
    "            uf_list.append(uf_systems[j][\"tag\"])\n",
    "            v_potential[k][\"tag\"]=vacant_spaces[k][\"tag\"]\n",
    "            v_potential[k][\"UF\"]=uf_list\n",
    "# print(v_potential)\n",
    "\n",
    "for couple_count in range(len(nearby_waste100)):\n",
    "    for couple in nearby_waste100:\n",
    "        \n",
    "        for index,item in enumerate(couple):\n",
    "            if vacant_spaces[couple[0]][\"building\"]!=wastes[couple[1]][\"source\"]:\n",
    "                print(couple,vacant_spaces[couple[0]][\"building\"],wastes[couple[1]][\"source\"],wastes[couple[1]][\"type\"])\n",
    "                if (wastes[couple[1]][\"type\"]==\"W5\") or (wastes[couple[1]][\"type\"]==\"W6\") or (wastes[couple[1]][\"type\"]==\"W7\"):\n",
    "                    if couple in nearby_waste100:\n",
    "                        print(couple,wastes[couple[1]][\"type\"])\n",
    "                        print(\"removed\",couple,wastes[couple[1]][\"type\"],vacant_spaces[couple[0]][\"building\"],wastes[couple[1]][\"source\"],wastes[couple[1]][\"type\"])\n",
    "                        nearby_waste100.remove(couple)\n",
    "        else:\n",
    "            print(couple,\"not in nearby_waste100\")\n",
    "                \n",
    "\n",
    "print(nearby_waste100)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw Graph with nodes and edges with coordinates\n",
    "G=nx.Graph()\n",
    "for i,j in vacant_spaces.items():\n",
    "    G.add_node(i)\n",
    "G.add_edges_from(nearby_waste100)\n",
    "nx.draw(G, with_labels=True, node_size=10)\n",
    "\n",
    "# Create a dictionary with vacant spaces and waste outputs them\n",
    "new_waste_dict = create_edge_dict(G)\n",
    "waste_dict = {}\n",
    "for i,k in new_waste_dict.items():\n",
    "    if i in vacant_spaces:\n",
    "        waste_dict[i]=k\n",
    "        \n",
    "#List of dictionaries we will use:\n",
    "# print(v_potential)\n",
    "# print(waste_dict)\n",
    "# print(uf_systems)\n",
    "\n",
    "# add needed inputs for each potential system into the v_potential dictionary\n",
    "v_potential_dict={}\n",
    "for i,k in v_potential.items():\n",
    "    v_potential_dict[i]={}\n",
    "    potential_systems = v_potential[i][\"UF\"]\n",
    "    for item in potential_systems:\n",
    "       v_potential_dict[i][item] = uf_systems[item][\"in\"]\n",
    "        \n",
    "#Design Rule 1.0 : Waste Availability\n",
    "    #if there are more than 2 found items assign that system to that vacant space\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Design Rule 3.0 : Sharing Existing Resources\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation of Data\n",
    "#Make a dictionary of found items nearby for each potential uf system\n",
    "found_dict={}\n",
    "\n",
    "for i,k in v_potential_dict.items():\n",
    "    found_dict[i]={}\n",
    "    for system,demanded in k.items():\n",
    "        found_dict[i][system]={}\n",
    "        found_dict[i][system][\"found\"]={}\n",
    "        found_dict[i][system][\"source\"]={}\n",
    "        found=[]\n",
    "        source=[]\n",
    "        for waste in waste_dict[i]:\n",
    "            for each in demanded: \n",
    "                available = wastes[waste][\"type\"]\n",
    "                source2 = wastes[waste][\"tag\"]\n",
    "                print(i,wastes[waste])\n",
    "                source_size = wastes[waste][\"size\"]\n",
    "                if each == available:\n",
    "                    found.append(available)\n",
    "                    source.append(source2)\n",
    "                    found_dict[i][system][\"found\"]=found\n",
    "                    found_dict[i][system][\"source\"]=source\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dictionary of missing for each potential uf system           \n",
    "for i,system in found_dict.items():\n",
    "    for uf in system:\n",
    "        missing=[]\n",
    "        found_dict[i][uf][\"missing\"]={}\n",
    "        for x,y in uf_systems.items():\n",
    "            for item in uf_systems[x][\"in\"]:\n",
    "                if uf == x:\n",
    "                    missing.append(item)\n",
    "                    found_dict[i][uf][\"missing\"]=missing\n",
    "        \n",
    "#In the dictionary missing items also contain found items\n",
    "for i,k in found_dict.items():\n",
    "    for system in k:\n",
    "        for item in (found_dict[i][system][\"found\"]):\n",
    "            if item in found_dict[i][system][\"missing\"]:\n",
    "                missing_list=found_dict[i][system][\"missing\"]\n",
    "                missing_list.remove(item)\n",
    "\n",
    "#reach sizes of duplicate items\n",
    "for i,k in found_dict.items():\n",
    "    for system in k:\n",
    "        found_items=found_dict[i][system][\"found\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a new list to the found dict -> for 1 waste source matching the size of space\n",
    "for space in found_dict:\n",
    "    for system in found_dict[space]:\n",
    "        found_dict[space][system][\"enough waste\"]=[]\n",
    "        found_dict[space][system][\"enough source\"]=[]\n",
    "        for item in found_dict[space][system][\"source\"]:\n",
    "            if wastes[item][\"size\"]==vacant_spaces[space][\"size\"]:\n",
    "                if found_dict[space][system][\"enough waste\"]==[]:\n",
    "                    print(space,system,item,wastes[item][\"type\"],\"1\")\n",
    "                    found_dict[space][system][\"enough waste\"].append(wastes[item][\"type\"])\n",
    "                    found_dict[space][system][\"enough source\"].append(wastes[item][\"tag\"])\n",
    "                    found_dict[space][system][\"found\"].remove(wastes[item][\"type\"])\n",
    "                    found_dict[space][system][\"source\"].remove(wastes[item][\"tag\"])\n",
    "                    break\n",
    "                elif found_dict[space][system][\"enough waste\"]!=[]:\n",
    "                    for waste in found_dict[space][system][\"enough waste\"]:\n",
    "                        if wastes[waste][\"type\"]!=wastes[item][\"type\"]:\n",
    "                            print(space,system,item,wastes[item][\"type\"],\"2\")\n",
    "                            found_dict[space][system][\"enough waste\"].append(wastes[item][\"type\"])\n",
    "                            found_dict[space][system][\"enough source\"].append(wastes[item][\"tag\"])\n",
    "                            found_dict[space][system][\"found\"].remove(wastes[item][\"type\"])\n",
    "                            found_dict[space][system][\"source\"].remove(wastes[item][\"tag\"])\n",
    "\n",
    "# print(found_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Make a dictionary holding each vacant space& found and repeating waste type & waste sources corresponding to found items\n",
    "duplicate_items={}\n",
    "for space,potential in found_dict.items():\n",
    "    duplicate_items[space]={}\n",
    "    for system, k in potential.items():\n",
    "        if len(found_dict[space][system][\"found\"])> 1:\n",
    "            found_items3=found_dict[space][system][\"found\"]\n",
    "            sources=[]\n",
    "            for index,items in enumerate(found_items3):\n",
    "                duplicate_items[space][items]={}\n",
    "                count=found_items3.count(items)\n",
    "                if count>1:\n",
    "                    items_str=str(items)\n",
    "                    sources.append(found_dict[space][system][\"source\"][index])\n",
    "                    duplicate_items[space][items][\"matching sources\"]=sources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the total size of found waste matches the vacant space size\n",
    "satisfying_duplicate={}\n",
    "not_enough_waste={}\n",
    "for space, k in duplicate_items.items():\n",
    "    print(space)\n",
    "    satisfying_duplicate[space]={}\n",
    "    not_enough_waste[space]={}\n",
    "    for key,value in k.items():\n",
    "        print(key)\n",
    "        satisfying_duplicate[space][key]={}\n",
    "        not_enough_waste[space][key]={}\n",
    "        waste_matched=[]\n",
    "        not_matched=[]\n",
    "        if duplicate_items[space][key]!=[]:\n",
    "            for m,n in duplicate_items[space][key].items():\n",
    "                matched=duplicate_items[space][key][m]\n",
    "                found_new=[]\n",
    "                for items in matched:\n",
    "                    found_new.append(items)\n",
    "                    waste_matched.append(wastes[items][\"size\"])\n",
    "                    if sum(waste_matched)==vacant_spaces[space][\"size\"]:\n",
    "                        print(space,vacant_spaces[space][\"size\"], waste_matched, \"add to found list and remove from missing\")\n",
    "                        print(found_new, \"is found\")\n",
    "                        print(waste_matched)\n",
    "                        satisfying_duplicate[space][key]=found_new\n",
    "                        break\n",
    "                    else:\n",
    "                        # print(sum(waste_matched),\"And\",vacant_spaces[space][\"size\"],items)\n",
    "                        not_matched.append(items)\n",
    "                        print(not_matched,\"is not matched\")\n",
    "                        not_enough_waste[space][key]=not_matched\n",
    "                    \n",
    "                    \n",
    "print(satisfying_duplicate)\n",
    "print(not_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate items if they are also in satisfying_duplicate items list\n",
    "for space,potential in found_dict.items():\n",
    "    for system in potential.keys():\n",
    "        for key, value in satisfying_duplicate.items():\n",
    "            for waste in value.keys():\n",
    "                if key==space:\n",
    "                        if len(found_dict[space][system][\"found\"])>0:\n",
    "                            print(\"there are found items\")\n",
    "                            if len(satisfying_duplicate[key][waste])>0:\n",
    "                                print(\"there are satisfying duplicate items\")\n",
    "                                if waste in found_dict[space][system][\"found\"]:\n",
    "                                    print(waste,\"is in found dict\",space,system)\n",
    "                                    found_items = found_dict[space][system][\"found\"]\n",
    "                                    found_dict[space][system][\"enough waste\"].append(waste)\n",
    "                                    for item in satisfying_duplicate[key][waste]:\n",
    "                                        found_dict[space][system][\"enough source\"].append(item)\n",
    "                                        found_dict[space][system][\"source\"].remove(item)\n",
    "                                    for found_range in range(len(found_items)):\n",
    "                                        for found in found_items:\n",
    "                                            print(found_items,space,system)\n",
    "                                            counter=found_items.count(found)\n",
    "                                            print(waste,counter,space,system)\n",
    "                                            if counter>1:\n",
    "                                                print(found,\"REMOVED\",space,system)  \n",
    "                                                found_items.remove(found)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate items if they are not in satisfying_duplicate items list\n",
    "print(found_dict[\"V2\"])\n",
    "for space in found_dict.keys():\n",
    "    for system in found_dict[space].keys():\n",
    "        found_items = found_dict[space][system][\"found\"]\n",
    "        missing_items = found_dict[space][system][\"missing\"]\n",
    "        duplicate=list_duplicates(found_items)\n",
    "        for key, value in satisfying_duplicate.items():\n",
    "            for waste in value.keys():\n",
    "                if key==space:\n",
    "                    for found in found_items:\n",
    "                        if found in duplicate:\n",
    "                            print(\"duplicate\",space,found,system)\n",
    "                            if satisfying_duplicate[space][found]==[]:\n",
    "                                print(\"duplicate not satisfying\",space,found,system)\n",
    "                                found_items.remove(found) \n",
    "                                if found not in missing_items:\n",
    "                                    missing_items.append(found)\n",
    "                                if (found in missing_items) and (found in found_items):\n",
    "                                    found_items.remove(found)            \n",
    "                                \n",
    "print(found_dict[\"V3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for space in found_dict:\n",
    "    for system in found_dict[space]:\n",
    "        source=found_dict[space][system][\"source\"]\n",
    "        for index,item in enumerate(source):\n",
    "            waste=wastes[item][\"type\"]\n",
    "            if waste in found_dict[space][system][\"found\"]:\n",
    "                print(\"found\",space,item,waste)\n",
    "            else:\n",
    "                source.remove(item)\n",
    "                print(item,\"removed from\",space,system,waste)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add circularity percentage to found_dict\n",
    "for space in found_dict:\n",
    "    for system in found_dict[space]:\n",
    "        found_dict[space][system][\"circularity\"]=[]\n",
    "        found=len(found_dict[space][system][\"enough waste\"])\n",
    "        missing=len(found_dict[space][system][\"missing\"])\n",
    "        total=found+missing\n",
    "        found_dict[space][system][\"circularity\"]=found/total\n",
    "# print(found_dict)   \n",
    "\n",
    "#make a duplicate of found dict, sort system based on circularities\n",
    "sorted_dict={}\n",
    "for space in found_dict:\n",
    "    system=sorted(found_dict[space], key=lambda x: (found_dict[space][x]['circularity']), reverse=True)  \n",
    "    sorted_dict[space]={} \n",
    "    for item in system:\n",
    "        values={}\n",
    "        values=(found_dict[space][item])\n",
    "        sorted_dict[space][item]=values\n",
    "\n",
    "# print(sorted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign Food Production System To Vacant Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the criteria is satisfied\n",
    "occupied={}\n",
    "used_waste=[]\n",
    "used_waste_source=[]\n",
    "used_waste_source_temp=[]\n",
    "new_edges=[]\n",
    "occupied_dict={}\n",
    "\n",
    "for space in sorted_dict:\n",
    "    print(\"looking for\", space)\n",
    "    print(\"for\",space,sorted_dict[space],\"is possible\")\n",
    "    occupied_dict[space]={}\n",
    "    occupied_dict[space][\"system\"]={}\n",
    "    occupied_dict[space][\"found\"]={}\n",
    "    occupied_dict[space][\"source\"]={}\n",
    "    occupied_dict[space][\"missing\"]={}\n",
    "    for index,system in enumerate(sorted_dict[space]):\n",
    "        print(\"looking for system\", system)\n",
    "        occupied[space]={}\n",
    "        occupied[space][\"system\"]={}\n",
    "        found_list=sorted_dict[space][system][\"enough waste\"]\n",
    "        sources_list=sorted_dict[space][system][\"enough source\"]\n",
    "        missing_list=sorted_dict[space][system][\"missing\"]\n",
    "        print(len(missing_list),\"is length for\",space,system)\n",
    "\n",
    "        if len(occupied[space][\"system\"])==0:\n",
    "            print(space,\"is not occupied run for\",system)\n",
    "            if len(missing_list)==0:    \n",
    "                for source in sources_list:\n",
    "                    if source in used_waste_source:\n",
    "                        print(used_waste_source,\"is used\",space,system)\n",
    "                        pass\n",
    "                    elif source not in used_waste_source:\n",
    "                        print(used_waste_source,\"is used\",space,system)\n",
    "                        occupied[space][\"system\"]=system\n",
    "                        occupied_dict[space][\"system\"]=system\n",
    "                        occupied_dict[space][\"found\"]=sorted_dict[space][system][\"enough waste\"]\n",
    "                        occupied_dict[space][\"source\"]=sorted_dict[space][system][\"enough source\"]\n",
    "                        for items in found_list:\n",
    "                            used_waste.append(items)\n",
    "                        used_waste_source.append(source)\n",
    "                        edge_tuple=(source,space)\n",
    "                        new_edges.append(edge_tuple)\n",
    "                        print(\"no missing items:\", space, system, \"assign\")\n",
    "                if len(occupied[space][\"system\"])>0:\n",
    "                    print(space,system,\"will break\")        \n",
    "                    break\n",
    "            elif len(missing_list)==1:\n",
    "                print(\"one item\",system,space)\n",
    "                for missing in missing_list:\n",
    "                    if missing in non_critical_items:\n",
    "                        print(\"one non critical item\",missing,system,space)\n",
    "                        for source in sources_list:\n",
    "                            if source not in used_waste_source:\n",
    "                                print(\"Used Non Critical Source\",source)\n",
    "                                occupied[space][\"system\"]=system\n",
    "                                occupied_dict[space][\"system\"]=system\n",
    "                                occupied_dict[space][\"found\"]=sorted_dict[space][system][\"enough waste\"]\n",
    "                                occupied_dict[space][\"source\"]=sorted_dict[space][system][\"enough source\"]\n",
    "                                occupied_dict[space][\"missing\"]=sorted_dict[space][system][\"missing\"]\n",
    "                                for items in found_list:\n",
    "                                    used_waste.append(items)\n",
    "                                used_waste_source.append(source)\n",
    "                                edge_tuple=(source,space)\n",
    "                                new_edges.append(edge_tuple)\n",
    "                                print(\"one non critical missing items:\", space, system, \"assign\")\n",
    "                            else:\n",
    "                                print(source,\"already used\")\n",
    "                    else:\n",
    "                        print(space,\"critical item missing:\",missing,\"for\",system)\n",
    "                if len(occupied[space][\"system\"])>0:\n",
    "                    print(space,system,\"will break\")        \n",
    "                    break \n",
    "            elif len(missing_list)==2:\n",
    "                print(\"two items\",system,space)\n",
    "                for missing in missing_list:\n",
    "                    print(\"two items\",missing)\n",
    "                    if missing in non_critical_items:\n",
    "                        print(\"two items\",missing,\"not critical\")\n",
    "                        for source in sources_list:\n",
    "                            if source not in used_waste_source:\n",
    "                                print(\"Used Non Critical Source\",source)\n",
    "                                occupied[space][\"system\"]=system\n",
    "                                occupied_dict[space][\"system\"]=system\n",
    "                                occupied_dict[space][\"found\"]=sorted_dict[space][system][\"enough waste\"]\n",
    "                                occupied_dict[space][\"source\"]=sorted_dict[space][system][\"enough source\"]\n",
    "                                occupied_dict[space][\"missing\"]=sorted_dict[space][system][\"missing\"]\n",
    "                                for items in found_list:\n",
    "                                    used_waste.append(items)\n",
    "                                print(\"two non critical missing items:\", space, system,\"assign\")\n",
    "                                print(space,occupied_dict[space])\n",
    "                                used_waste_source.append(source)\n",
    "                                edge_tuple=(source,space)\n",
    "                                new_edges.append(edge_tuple)\n",
    "                    else:\n",
    "                        print(space,\"critical item missing:\",missing,\"for\",system)\n",
    "                if len(occupied[space][\"system\"])>0:\n",
    "                    print(space,system,\"will break\")        \n",
    "                    break  \n",
    "for space in occupied_dict:\n",
    "    if len(occupied_dict[space][\"system\"])!=0:\n",
    "        print(space,occupied_dict[space][\"system\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create New List To Be Used In Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(occupied)  \n",
    "# print(used_waste_source) \n",
    "# print(new_edges)\n",
    "# print(occupied_dict)\n",
    "#add circularity & outputs to occupied_dict\n",
    "for space in occupied_dict:\n",
    "    occupied_dict[space][\"circularity\"]={}\n",
    "    occupied_dict[space][\"outputs\"]={}\n",
    "    occupied_dict[space][\"supplements\"]={}\n",
    "    if len(occupied_dict[space][\"system\"])!=0:\n",
    "        system=occupied_dict[space][\"system\"]\n",
    "        outputs=(uf_systems[system][\"out\"])\n",
    "        supplements=uf_systems[system][\"supplement\"]\n",
    "        occupied_dict[space][\"circularity\"]=found_dict[space][system][\"circularity\"]\n",
    "        occupied_dict[space][\"supplements\"]=supplements\n",
    "        occupied_dict[space][\"outputs\"]=outputs\n",
    "\n",
    "#remove empty spaces from occupied_dict\n",
    "remove=[]\n",
    "for space in occupied_dict:\n",
    "    if len(occupied_dict[space][\"system\"])==0:\n",
    "        remove.append(space)\n",
    "for items in remove:\n",
    "    occupied_dict.pop(items)\n",
    "# print(\"occupied\",occupied_dict)\n",
    "\n",
    "#remove assigned spaces from found_dict\n",
    "remove2=[]\n",
    "for space in sorted_dict:\n",
    "    if space in occupied_dict:\n",
    "        remove2.append(space)\n",
    "for items in remove2:\n",
    "    sorted_dict.pop(items)\n",
    "# print(\"non occupied\",sorted_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Assign Food Producing Supplementary Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for a system that can supply needed supplement\n",
    "#put the findings in a dictionary\n",
    "v_supplement_fs={}\n",
    "for space in occupied_dict:\n",
    "    v_supplement_fs[space]={}\n",
    "    v_supplement_fs[space][\"supplement\"]={}\n",
    "    v_supplement_fs[space][\"fs_system\"]={}\n",
    "    v_supplement_fs[space][\"supplement\"]={}\n",
    "    v_supplement_fs[space][\"supplement source\"]={}\n",
    "    v_supplement_fs[space][\"fs_demand\"]={}\n",
    "    v_supplement_fs[space][\"fs_demand source\"]={}\n",
    "    v_supplement_fs[space][\"potential source\"]={}\n",
    "    supplement=occupied_dict[space][\"supplements\"]\n",
    "    if supplement!=None:\n",
    "        for item in supplement:\n",
    "            if item==\"S2\": \n",
    "                for i in uf_systems:\n",
    "                    out=uf_systems[i][\"out\"]\n",
    "                    if \"S2\" in out:\n",
    "                        print(\"maybe\",space, i,uf_systems[i][\"in\"])\n",
    "                        v_supplement_fs[space][\"fs_system\"]=i\n",
    "                        v_supplement_fs[space][\"supplement\"]=item\n",
    "                        v_supplement_fs[space][\"fs_demand\"]=uf_systems[i][\"in\"]\n",
    "    else:\n",
    "        v_supplement_fs[space][\"fs_system\"]=None\n",
    "\n",
    "print(v_supplement_fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#created a dictionary for spaces which need supplement to store system, supplementing neighbor and supplement type\n",
    "#for each space found what kind of system and supplement and input is necessary \n",
    "\n",
    "#look neighbors of supplement needing space to see if there is a potential neighbor\n",
    "for space in v_supplement_fs:\n",
    "    potential=[]\n",
    "    for space2,neighbor in nearby_space100:\n",
    "        if space==space2:\n",
    "            if (len(v_supplement_fs[space][\"supplement source\"])==0) and (len(v_supplement_fs[space][\"fs_system\"])!=0):\n",
    "                # print(neighbor,\"is available\")\n",
    "                system=v_supplement_fs[space][\"fs_system\"]\n",
    "                print(system,\"system\")\n",
    "                print(vacant_spaces[space][\"size\"],vacant_spaces[neighbor][\"size\"])\n",
    "                if (vacant_spaces[space][\"size\"]==vacant_spaces[neighbor][\"size\"]) and (vacant_spaces[neighbor][\"structure\"]>=uf_systems[system][\"weight\"]) and (vacant_spaces[neighbor][\"solar\"]>=uf_systems[system][\"solar\"]):\n",
    "                    potential.append(neighbor)\n",
    "                    # print(space,potential)\n",
    "                    v_supplement_fs[space][\"potential source\"]=potential\n",
    "        elif space==neighbor:\n",
    "                print(neighbor,space2,\"reverse is available\")\n",
    "                if (len(v_supplement_fs[space][\"supplement source\"])==0) and (len(v_supplement_fs[space][\"fs_system\"])!=0):\n",
    "                    print(space2,\"is available\")\n",
    "                    system=v_supplement_fs[space][\"fs_system\"]\n",
    "                    if (vacant_spaces[space][\"size\"]==vacant_spaces[space2][\"size\"]) and (vacant_spaces[space2][\"structure\"]>=uf_systems[system][\"weight\"]) and (vacant_spaces[space2][\"solar\"]>=uf_systems[system][\"solar\"]):\n",
    "                        potential.append(space2)\n",
    "                        print(potential)\n",
    "                        print(space,potential)\n",
    "                        print(space,\"matches\",space2,\"and\",system)\n",
    "                        v_supplement_fs[space][\"potential source\"]=potential\n",
    "                    else:\n",
    "                        print(\"structure\",space,vacant_spaces[space2][\"structure\"],system,uf_systems[system][\"weight\"])\n",
    "                        print(\"sun\",space,vacant_spaces[space2][\"solar\"],system,uf_systems[system][\"solar\"])\n",
    "                else:\n",
    "                    print(space,space2,\"not available\",v_supplement_fs[space][\"fs_system\"],\"no need for supplement\")\n",
    "# print(v_supplement_fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if potential sources have fs_demand\n",
    "for space in v_supplement_fs:\n",
    "    potential=v_supplement_fs[space][\"potential source\"]\n",
    "    if len(v_supplement_fs[space][\"supplement source\"])==0:\n",
    "        # print(vacant,len(v_supplement_fs[space][\"supplement source\"]),\"---\",v_supplement_fs[space][\"supplement source\"])\n",
    "        for vacant in potential:\n",
    "            nearby_list=waste_dict[vacant]\n",
    "            for nearby in nearby_list:\n",
    "                print(vacant, nearby,\"is\",wastes[nearby][\"type\"])\n",
    "                if nearby not in used_waste_source:\n",
    "                    if wastes[nearby][\"size\"]==vacant_spaces[space][\"size\"]:\n",
    "                        print(nearby,\"not used\")\n",
    "                        if v_supplement_fs[space][\"fs_demand\"]==wastes[nearby][\"type\"]:\n",
    "                            print(\"for\",space,vacant,\"is potential and has\",nearby,\"as a source of\",wastes[nearby][\"type\"])\n",
    "                            v_supplement_fs[space][\"supplement source\"]=vacant\n",
    "                            print(v_supplement_fs[space][\"supplement source\"])\n",
    "                            v_supplement_fs[space][\"fs_demand source\"]=nearby\n",
    "                            print(v_supplement_fs[space][\"fs_demand source\"])\n",
    "                            used_waste_source.append(nearby)\n",
    "                            edge_tuple1=(nearby,vacant)\n",
    "                            edge_tuple2=(vacant,space)\n",
    "                            new_edges.append(edge_tuple1)\n",
    "                            new_edges.append(edge_tuple2)\n",
    "                            if len(v_supplement_fs[space][\"supplement source\"])>0:\n",
    "                                # print(space,system,\"will break\")        \n",
    "                                break\n",
    "\n",
    "            if len(v_supplement_fs[space][\"supplement source\"])>0:\n",
    "                            # print(space,system,\"will break2\")        \n",
    "                            break\n",
    "                    \n",
    "# print(v_supplement_fs)  \n",
    "# print(used_waste_source) \n",
    "# print(new_edges)     \n",
    "print(\"occupied\",occupied_dict)\n",
    "\n",
    "for space in v_supplement_fs:\n",
    "    if len(v_supplement_fs[space][\"fs_system\"])!=0:\n",
    "        if len(v_supplement_fs[space][\"supplement source\"])!=0:\n",
    "            occ=v_supplement_fs[space][\"supplement source\"]\n",
    "            occupied_dict[occ]={}\n",
    "            occupied_dict[occ][\"found\"]=v_supplement_fs[space][\"fs_demand\"]\n",
    "            occupied_dict[occ][\"system\"]=v_supplement_fs[space][\"fs_system\"]\n",
    "            system=occupied_dict[occ][\"system\"]\n",
    "            occupied_dict[occ][\"source\"]=v_supplement_fs[space][\"fs_demand source\"]\n",
    "            occupied_dict[occ][\"supplements\"]=uf_systems[system][\"supplement\"]\n",
    "print(occupied_dict)\n",
    "\n",
    "#make a dictionary of source: waste type: size: receiver:tuple\n",
    "network_dict={}\n",
    "for source,space in new_edges:\n",
    "    type_list=[]\n",
    "    network_dict[source]={}\n",
    "    network_dict[source][\"type\"]={}\n",
    "    network_dict[source][\"size\"]={}\n",
    "    network_dict[source][\"receiver\"]={}\n",
    "\n",
    "for source,space in new_edges:\n",
    "    network_dict[source][\"receiver\"]=space\n",
    "    if source in wastes:\n",
    "        network_dict[source][\"type\"]=wastes[source][\"type\"]\n",
    "        network_dict[source][\"size\"]=wastes[source][\"size\"]\n",
    "    elif source in vacant_spaces:\n",
    "        network_dict[source][\"size\"]=vacant_spaces[source][\"size\"]\n",
    "        network_dict[source][\"type\"]=occupied_dict[source][\"found\"]\n",
    "    \n",
    "print(network_dict)\n",
    "print(occupied_dict)\n",
    "for space in v_supplement_fs:\n",
    "    if len(v_supplement_fs[space][\"fs_system\"])!=0:\n",
    "        print(\"work\")\n",
    "        if len(v_supplement_fs[space][\"supplement source\"])!=0:\n",
    "            occ=v_supplement_fs[space][\"supplement source\"]\n",
    "            occupied_dict[occ]={}\n",
    "            print(occupied_dict)\n",
    "            occupied_dict[occ][\"found\"]=v_supplement_fs[space][\"fs_demand\"]\n",
    "            occupied_dict[occ][\"system\"]=v_supplement_fs[space][\"fs_system\"]\n",
    "            occupied_dict[occ][\"source\"]=v_supplement_fs[space][\"fs_demand source\"]\n",
    "print(occupied_dict)\n",
    "\n",
    "#make a dictionary of source: waste type: size: receiver:tuple\n",
    "network_dict={}\n",
    "for source,space in new_edges:\n",
    "    type_list=[]\n",
    "    network_dict[source]={}\n",
    "    network_dict[source][\"type\"]={}\n",
    "    network_dict[source][\"size\"]={}\n",
    "    network_dict[source][\"receiver\"]={}\n",
    "\n",
    "for source,space in new_edges:\n",
    "    network_dict[source][\"receiver\"]=space\n",
    "    if source in wastes:\n",
    "        network_dict[source][\"type\"]=wastes[source][\"type\"]\n",
    "        network_dict[source][\"size\"]=wastes[source][\"size\"]\n",
    "    elif source in vacant_spaces:\n",
    "        network_dict[source][\"size\"]=vacant_spaces[source][\"size\"]\n",
    "        network_dict[source][\"type\"]=occupied_dict[source][\"found\"]\n",
    "\n",
    "print(network_dict)\n",
    "\n",
    "#now we have food supplying supplementary systems\n",
    "#we still need to check if these systems need supplements\n",
    "for space in occupied_dict: \n",
    "    system=occupied_dict[space][\"system\"]\n",
    "    # print(system)\n",
    "    # print(uf_systems[system][\"supplement\"])\n",
    "    value=uf_systems[system][\"supplement\"]\n",
    "    for supplement in value:\n",
    "        if (supplement==\"S5\") or (supplement==\"S4\"):\n",
    "            v_supplement_fs[space]={}\n",
    "            v_supplement_fs[space][\"supplement\"]=supplement\n",
    "            for uf in uf_systems:\n",
    "                for out in uf_systems[uf][\"out\"]:\n",
    "                    if supplement == out:\n",
    "                        v_supplement_fs[space][\"fs_system\"]=uf\n",
    "                        v_supplement_fs[space][\"fs_demand\"]=uf_systems[uf][\"in\"]\n",
    "            v_supplement_fs[space][\"supplement source\"]={}\n",
    "            v_supplement_fs[space][\"fs_demand source\"]={}\n",
    "            v_supplement_fs[space][\"potential source\"]={}\n",
    "print(v_supplement_fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a potential list\n",
    "for space in v_supplement_fs:\n",
    "    potential=[]\n",
    "    print(space)\n",
    "    for space2,neighbor in nearby_space100:  \n",
    "        if (space==space2):\n",
    "            print(space2,neighbor)\n",
    "            if (len(v_supplement_fs[space][\"supplement source\"])==0) and (len(v_supplement_fs[space][\"fs_system\"])!=0):\n",
    "                print(neighbor,\"is available\")\n",
    "                system=v_supplement_fs[space][\"fs_system\"]\n",
    "                if (vacant_spaces[space][\"size\"]==vacant_spaces[neighbor][\"size\"]) and (vacant_spaces[neighbor][\"structure\"]>=uf_systems[system][\"weight\"]) and (vacant_spaces[neighbor][\"solar\"]>=uf_systems[system][\"solar\"]):\n",
    "                    potential.append(neighbor)\n",
    "                    print(potential)\n",
    "                    print(space,potential)\n",
    "                    v_supplement_fs[space][\"potential source\"]=potential\n",
    "                else:\n",
    "                    print(space,vacant_spaces[neighbor][\"structure\"],system,uf_systems[system][\"weight\"])\n",
    "            else:\n",
    "                print(space,neighbor,\"not available\",v_supplement_fs[space][\"fs_system\"],\"no need for supplement\")\n",
    "        elif space==neighbor:\n",
    "            print(neighbor,space2,\"reverse is available\")\n",
    "            if (len(v_supplement_fs[space][\"supplement source\"])==0) and (len(v_supplement_fs[space][\"fs_system\"])!=0):\n",
    "                print(space2,\"is available\")\n",
    "                system=v_supplement_fs[space][\"fs_system\"]\n",
    "                if (vacant_spaces[space][\"size\"]==vacant_spaces[space2][\"size\"]) and (vacant_spaces[space2][\"structure\"]>=uf_systems[system][\"weight\"]) and (vacant_spaces[space2][\"solar\"]>=uf_systems[system][\"solar\"]):\n",
    "                    potential.append(space2)\n",
    "                    print(potential)\n",
    "                    print(space,potential)\n",
    "                    print(space,\"matches\",space2,\"and\",system)\n",
    "                    v_supplement_fs[space][\"potential source\"]=potential\n",
    "                else:\n",
    "                    print(\"structure\",space,vacant_spaces[space2][\"structure\"],system,uf_systems[system][\"weight\"])\n",
    "                    print(\"sun\",space,vacant_spaces[space2][\"solar\"],system,uf_systems[system][\"solar\"])\n",
    "                    print(\"size\",vacant_spaces[space][\"size\"]==vacant_spaces[space2][\"size\"])\n",
    "            else:\n",
    "                print(space,space2,\"not available\",v_supplement_fs[space][\"fs_system\"],\"no need for supplement\")\n",
    "print(v_supplement_fs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if potential sources have fs_demand\n",
    "print(used_waste_source)\n",
    "for space in v_supplement_fs:\n",
    "    potential=v_supplement_fs[space][\"potential source\"]\n",
    "    if len(v_supplement_fs[space][\"supplement source\"])==0:\n",
    "        for vacant in potential:\n",
    "            found=[]\n",
    "            found_source=[]\n",
    "            nearby_list=waste_dict[vacant]\n",
    "            for nearby in nearby_list:\n",
    "                print(vacant, nearby,\"is\",wastes[nearby][\"type\"])\n",
    "                if nearby not in used_waste_source:\n",
    "                    if wastes[nearby][\"size\"]==vacant_spaces[space][\"size\"]:\n",
    "                        print(nearby,\"not used\")\n",
    "                        found.append(wastes[nearby][\"type\"])\n",
    "                        found_source.append(nearby)\n",
    "                        print(found)\n",
    "                        if v_supplement_fs[space][\"fs_demand\"]==found:\n",
    "                            print(\"for\",space,vacant,\"is potential and has\",nearby,\"as a source of\",wastes[nearby][\"type\"])\n",
    "                            v_supplement_fs[space][\"supplement source\"]=vacant\n",
    "                            print(v_supplement_fs[space][\"supplement source\"])\n",
    "                            v_supplement_fs[space][\"fs_demand source\"]=found_source\n",
    "                            print(v_supplement_fs[space][\"fs_demand source\"])\n",
    "                            for x in found_source:\n",
    "                                used_waste_source.append(x)\n",
    "                                edge_tuple1=(x,vacant)\n",
    "                                new_edges.append(edge_tuple1)\n",
    "                            edge_tuple2=(vacant,space)\n",
    "                            new_edges.append(edge_tuple2)\n",
    "                            print(\"new edges added\",new_edges)\n",
    "                            if len(v_supplement_fs[space][\"supplement source\"])>0:\n",
    "                                # print(space,system,\"will break\")        \n",
    "                                break\n",
    "\n",
    "            if len(v_supplement_fs[space][\"supplement source\"])>0:\n",
    "                            # print(space,system,\"will break2\")        \n",
    "                            break\n",
    "                    \n",
    "print(v_supplement_fs) \n",
    "# print(new_edges)\n",
    "# print(used_waste_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(occupied_dict)\n",
    "for space in v_supplement_fs:\n",
    "    if len(v_supplement_fs[space][\"fs_system\"])!=0:\n",
    "        if len(v_supplement_fs[space][\"supplement source\"])!=0:\n",
    "            occ=v_supplement_fs[space][\"supplement source\"]\n",
    "            occupied_dict[occ]={}\n",
    "            occupied_dict[occ][\"found\"]=v_supplement_fs[space][\"fs_demand\"]\n",
    "            occupied_dict[occ][\"system\"]=v_supplement_fs[space][\"fs_system\"]\n",
    "            system=v_supplement_fs[space][\"fs_system\"]\n",
    "            print(occ,system)\n",
    "            print(len(uf_systems[system]))\n",
    "            print(len(occupied_dict[occ][\"found\"]))\n",
    "            occupied_dict[occ][\"source\"]=v_supplement_fs[space][\"fs_demand source\"]\n",
    "            occupied_dict[occ][\"outputs\"]=v_supplement_fs[space][\"supplement\"]\n",
    "            occupied_dict[occ][\"supplements\"]=uf_systems[system][\"supplement\"]\n",
    "            occupied_dict[occ][\"circularity\"]=1.0\n",
    "print(occupied_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dictionary of source: waste type: size: receiver:tuple\n",
    "network_dict={}\n",
    "for source,space in new_edges:\n",
    "    type_list=[]\n",
    "    network_dict[source]={}\n",
    "    network_dict[source][\"type\"]={}\n",
    "    network_dict[source][\"size\"]={}\n",
    "    network_dict[source][\"receiver\"]={}\n",
    "\n",
    "for source,space in new_edges:\n",
    "    network_dict[source][\"receiver\"]=space\n",
    "    if source in wastes:\n",
    "        network_dict[source][\"type\"]=wastes[source][\"type\"]\n",
    "        network_dict[source][\"size\"]=wastes[source][\"size\"]\n",
    "    elif source in vacant_spaces:\n",
    "        network_dict[source][\"size\"]=vacant_spaces[source][\"size\"]\n",
    "        network_dict[source][\"type\"]=occupied_dict[source][\"outputs\"]\n",
    "    \n",
    "# print(network_dict)\n",
    "\n",
    "for space in occupied_dict:\n",
    "    if occupied_dict[space][\"system\"]==None:\n",
    "        occupied_dict.remove(space)\n",
    "print(new_edges)\n",
    "print(network_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacant_spaces2=vacant_spaces.copy()\n",
    "\n",
    "for space in occupied_dict:\n",
    "    vacant_spaces2.pop(space)\n",
    "\n",
    "file = \"vacant spaces_bigger radius2.txt\"\n",
    "with open(str(file), 'w') as outfile:\n",
    "    try:\n",
    "        json.dump(vacant_spaces2, outfile)\n",
    "        print(file + \" has been updated successfully\")\n",
    "    except:\n",
    "        print(\"Problem with updating file\")\n",
    "\n",
    "\n",
    "wastes2=wastes.copy()\n",
    "\n",
    "for waste in used_waste_source:\n",
    "    wastes2.pop(waste)\n",
    "\n",
    "file = \"available waste 3.txt\"\n",
    "with open(str(file), 'w') as outfile:\n",
    "    try:\n",
    "        json.dump(wastes2, outfile)\n",
    "        print(file + \" has been updated successfully\")\n",
    "    except:\n",
    "        print(\"Problem with updating file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine wastes and vacant_spaces\n",
    "workbook = load_workbook(filename=\"coordintes_xyz.xlsx\")\n",
    "workbook.sheetnames\n",
    "sheet1 = workbook.worksheets[0]\n",
    "sheet2 = workbook.worksheets[1]\n",
    "\n",
    "new_edges2=[]\n",
    "for space in network_dict:\n",
    "    sources=(network_dict[space][\"receiver\"])\n",
    "    tuples=(space,sources)\n",
    "    new_edges2.append(tuples)\n",
    "print(new_edges2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update locations in dictionary based on excel worksheet\n",
    "coordinate_list1=[]\n",
    "for value in sheet1.iter_rows(min_row=2, values_only=True):\n",
    "    for index,item in enumerate(value):\n",
    "            coordinate=(value[0],value[1],value[2])\n",
    "    coordinate_list1.append(coordinate)\n",
    "\n",
    "for index1,space in enumerate(vacant_spaces):\n",
    "    for index2,coordinate in enumerate(coordinate_list1):\n",
    "        if index1==index2:\n",
    "            vacant_spaces[space][\"location\"]=coordinate_list1[index2]\n",
    "\n",
    "\n",
    "#update locations in dictionary based on excel worksheet\n",
    "\n",
    "workbook = load_workbook(filename=\"Node_Information_TU.xlsx\")\n",
    "workbook.sheetnames\n",
    "sheet1 = workbook.worksheets[0]\n",
    "sheet2 = workbook.worksheets[1]\n",
    "wastes2={}\n",
    "for value in sheet2.iter_rows(min_row=2, values_only=True):\n",
    "    for index,item in enumerate(value):\n",
    "        wastes2[value[0]]={}\n",
    "        wastes2[value[0]][\"location\"]=value[1]\n",
    "        wastes2[value[0]][\"source\"]=value[2]\n",
    "        wastes2[value[0]][\"type\"]=value[3]\n",
    "        wastes2[value[0]][\"quantity\"]=value[4]\n",
    "        wastes2[value[0]][\"tag\"]=value[5]\n",
    "        wastes2[value[0]][\"node_type\"]=\"waste\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#update locations in dictionary based on excel worksheet\n",
    "\n",
    "workbook = load_workbook(filename=\"coordintes_xyz.xlsx\")\n",
    "workbook.sheetnames\n",
    "sheet1 = workbook.worksheets[0]\n",
    "sheet2 = workbook.worksheets[1]\n",
    "\n",
    "coordinate_list2=[]\n",
    "for value in sheet2.iter_rows(min_row=2, values_only=True):\n",
    "    for index,item in enumerate(value):\n",
    "            coordinate=(value[0],value[1],value[2])\n",
    "    coordinate_list2.append(coordinate)\n",
    "\n",
    "for index1,space in enumerate(wastes2):\n",
    "    for index2,coordinate in enumerate(coordinate_list2): \n",
    "        if index1==index2:\n",
    "            # print(index2,coordinate,space)\n",
    "            wastes2[space][\"location\"]=coordinate_list2[index2]\n",
    "\n",
    "combined_dict=vacant_spaces.copy()\n",
    "combined_dict.update(wastes2)\n",
    "\n",
    "coordinates=[]\n",
    "#make a coordinate list for new_edges [(coordinates1,coordinates2),(coordinates1,coordinates2),(coordinates1,coordinates2)]\n",
    "for item in new_edges2:\n",
    "        # print(item)\n",
    "        coordinate_tuple=(combined_dict[item[0]][\"location\"],combined_dict[item[1]][\"location\"])\n",
    "        print(item,coordinate_tuple)\n",
    "        coordinates.append(coordinate_tuple)\n",
    "\n",
    "print(coordinates,\"is coordinates\")\n",
    "print(new_edges2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_edges_dict={}\n",
    "for index,couple in enumerate(coordinates):\n",
    "        export_edges_dict[index]={}\n",
    "        export_edges_dict[index][\"coordinate\"]=couple\n",
    "\n",
    "export_edges_dict={}\n",
    "for index,waste in enumerate(network_dict):\n",
    "        export_edges_dict[index]={}\n",
    "        export_edges_dict[index][\"type\"]=network_dict[waste][\"type\"]\n",
    "        export_edges_dict[index][\"connection\"]=coordinates[index]\n",
    "\n",
    "print(export_edges_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a dictionary of all spaces and systems\n",
    "export_dict={}\n",
    "for space in vacant_spaces:\n",
    "    export_dict[space]={}\n",
    "    export_dict[space][\"location\"]={}\n",
    "    export_dict[space][\"system\"]={}\n",
    "for space in vacant_spaces:\n",
    "    if space in occupied_dict:\n",
    "        export_dict[space][\"system\"]=occupied_dict[space][\"system\"]\n",
    "        export_dict[space][\"location\"]=combined_dict[space][\"location\"]\n",
    "    else:\n",
    "        export_dict[space][\"system\"]=None\n",
    "        export_dict[space][\"location\"]=None\n",
    "print(export_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"occupied nodes2.txt\"\n",
    "with open(str(file), 'w') as outfile:\n",
    "    try:\n",
    "        json.dump(export_dict, outfile)\n",
    "        print(file + \" has been updated successfully\")\n",
    "    except:\n",
    "        print(\"Problem with updating file\")\n",
    "\n",
    "file = \"new_edges2.txt\"\n",
    "with open(str(file), 'w') as outfile:\n",
    "    try:\n",
    "        json.dump(new_edges, outfile)\n",
    "        print(file + \" has been updated successfully\")\n",
    "    except:\n",
    "        print(\"Problem with updating file\")\n",
    "\n",
    "file = \"new_edges_dict2.txt\"\n",
    "with open(str(file), 'w') as outfile:\n",
    "    try:\n",
    "        json.dump(export_edges_dict, outfile)\n",
    "        print(file + \" has been updated successfully\")\n",
    "    except:\n",
    "        print(\"Problem with updating file\")        \n",
    "\n",
    "file = \"coordinates2.txt\"\n",
    "with open(str(file), 'w') as outfile:\n",
    "    try:\n",
    "        json.dump(coordinates, outfile)\n",
    "        print(file + \" has been updated successfully\")\n",
    "    except:\n",
    "        print(\"Problem with updating file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. INCREASING RADIUS"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ceab667343e9d59e560dc535b596d8ce99779dfe6a9fc32021184bc08a53fa46"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('earthy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
